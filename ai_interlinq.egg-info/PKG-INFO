Metadata-Version: 2.4
Name: ai-interlinq
Version: 0.1.0
Summary: Fast AI-to-AI communication library with shared token encryption
Home-page: https://github.com/mupoese/AI-Interlinq
Author: mupoese
License: GPL-2.0
Project-URL: Homepage, https://github.com/mupoese/AI-Interlinq
Project-URL: Repository, https://github.com/mupoese/AI-Interlinq
Project-URL: Issues, https://github.com/mupoese/AI-Interlinq/issues
Project-URL: Documentation, https://github.com/mupoese/AI-Interlinq/blob/main/README.md
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: GNU General Public License v2 (GPLv2)
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Communications
Classifier: Topic :: Security :: Cryptography
Classifier: Topic :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: cryptography>=3.4.0
Requires-Dist: msgpack>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.18.0; extra == "dev"
Requires-Dist: black>=21.0.0; extra == "dev"
Requires-Dist: flake8>=3.9.0; extra == "dev"
Requires-Dist: mypy>=0.910; extra == "dev"
Requires-Dist: pytest-cov>=3.0.0; extra == "dev"
Provides-Extra: mqtt
Requires-Dist: asyncio-mqtt>=0.11.0; extra == "mqtt"
Provides-Extra: all
Requires-Dist: ai-interlinq[dev,mqtt]; extra == "all"
Requires-Dist: msgpack-python>=0.5.6; extra == "all"
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# AI-Interlinq

A high-performance AI-to-AI communication library with shared token encryption for fast, secure communication between AI models and agents.

## ğŸš€ Features

- **ğŸ” Shared Token Encryption**: Secure communication using shared encryption keys
- **âš¡ High Performance**: Optimized for speed with minimal latency  
- **ğŸ—ï¸ Standardized Protocol**: Consistent message formats and communication patterns
- **ğŸ”„ Async Support**: Full asynchronous communication capabilities
- **ğŸ“Š Performance Monitoring**: Built-in metrics and performance tracking
- **ğŸ›¡ï¸ Security First**: Industry-standard encryption and authentication
- **ğŸ”Œ Easy Integration**: Simple API for quick AI system integration

## ğŸ“¦ Installation

```bash
pip install ai-interlinq
```

For development:
```bash
pip install ai-interlinq[dev]
```

## ğŸ¯ Quick Start

### Basic Communication

```python
import asyncio
from ai_interlinq import TokenManager, EncryptionHandler, CommunicationProtocol, MessageHandler
from ai_interlinq.core.communication_protocol import MessageType, Priority

async def basic_example():
    # Setup shared encryption key
    shared_key = "your_shared_secret_key"
    
    # Initialize components
    token_manager = TokenManager(default_ttl=3600)
    encryption = EncryptionHandler(shared_key)
    protocol = CommunicationProtocol("agent_001")
    message_handler = MessageHandler("agent_001", token_manager, encryption)
    
    # Create session and generate token
    session_id = "session_001"
    token = token_manager.generate_token(session_id)
    
    # Create message
    message = protocol.create_message(
        recipient_id="agent_002",
        message_type=MessageType.REQUEST,
        command="process_data",
        data={"task": "analyze", "payload": "sample_data"},
        session_id=session_id,
        priority=Priority.HIGH
    )
    
    # Send message
    success = await message_handler.send_message(message)
    if success:
        print("âœ… Message sent successfully!")

# Run example
asyncio.run(basic_example())
```

### Message Handling

```python
async def setup_message_handler():
    # Register command handlers
    async def handle_process_data(message):
        data = message.payload.data
        print(f"Processing: {data['task']} - {data['payload']}")
        
        # Send response
        response = protocol.create_message(
            recipient_id=message.header.sender_id,
            message_type=MessageType.RESPONSE,
            command="process_complete",
            data={"result": "processed", "status": "success"},
            session_id=message.header.session_id
        )
        await message_handler.send_message(response)
    
    message_handler.register_command_handler("process_data", handle_process_data)
    
    # Process incoming messages
    processed = await message_handler.process_messages(session_id)
    print(f"Processed {processed} messages")
```

## ğŸ—ï¸ Architecture

### Core Components

- **TokenManager**: Handles secure token generation, validation, and lifecycle
- **EncryptionHandler**: Provides encryption/decryption using shared keys
- **CommunicationProtocol**: Defines message structure and validation rules
- **MessageHandler**: Manages message queuing, routing, and processing

### Message Structure

```python
{
    "header": {
        "message_id": "unique_id",
        "message_type": "request|response|notification|error",
        "sender_id": "agent_001", 
        "recipient_id": "agent_002",
        "timestamp": 1234567890.123,
        "priority": "low|normal|high|critical",
        "session_id": "session_001",
        "protocol_version": "1.0"
    },
    "payload": {
        "command": "process_data",
        "data": {"key": "value"},
        "metadata": {"optional": "metadata"}
    },
    "signature": "optional_signature"
}
```

## ğŸ” Security Features

### Token-Based Authentication
- Secure token generation using cryptographically strong random values
- Configurable token expiration and automatic cleanup
- Session-based token management

### Encryption
- Industry-standard AES encryption via Fernet
- PBKDF2 key derivation for enhanced security
- Message integrity verification with SHA-256 hashing

### Example: Secure Communication Setup

```python
# Generate shared key
encryption = EncryptionHandler()
shared_key = encryption.generate_shared_key()

# Setup encryption for multiple agents
agent_a_encryption = EncryptionHandler(shared_key)
agent_b_encryption = EncryptionHandler(shared_key)

# Both agents can now communicate securely
success, encrypted = agent_a_encryption.encrypt_message("Hello Agent B!")
success, decrypted = agent_b_encryption.decrypt_message(encrypted)
```

## âš¡ Performance

AI-Interlinq is optimized for high-throughput, low-latency communication:

- **Message Creation**: 10,000+ messages/second
- **Serialization**: 8,000+ messages/second  
- **Encryption**: 5,000+ messages/second
- **End-to-End Latency**: < 10ms for standard messages

### Performance Monitoring

```python
from ai_interlinq.utils.performance import PerformanceMonitor

monitor = PerformanceMonitor()

# Time operations
timer_id = monitor.start_timer("message_processing")
# ... process message ...
duration = monitor.end_timer(timer_id)

# Record custom metrics
monitor.record_metric("queue_size", 42)
monitor.increment_counter("messages_processed")

# Get statistics
stats = monitor.get_all_stats()
latency_percentiles = monitor.get_latency_percentiles("message_processing")
```

## ğŸ“š Advanced Usage

### Priority-Based Message Queuing

```python
# Messages are automatically queued by priority
message_high = protocol.create_message(..., priority=Priority.HIGH)
message_normal = protocol.create_message(..., priority=Priority.NORMAL)

# High priority messages are processed first
await message_handler.process_messages(session_id)
```

### Request-Response Pattern

```python
# Send request and wait for response
request = protocol.create_message(
    recipient_id="agent_002",
    message_type=MessageType.REQUEST,
    command="get_status",
    data={},
    session_id=session_id
)

response = await message_handler.send_request_and_wait_response(
    request, timeout=30.0
)

if response:
    print(f"Status: {response.payload.data['status']}")
```

### Error Handling

```python
# Automatic error responses
try:
    # Process message
    result = process_data(message.payload.data)
except Exception as e:
    error_response = protocol.create_error_response(
        original_message=message,
        error_code="PROCESSING_ERROR", 
        error_description=str(e)
    )
    await message_handler.send_message(error_response)
```

## ğŸ§ª Testing

Run tests:
```bash
pytest tests/
```

Run with coverage:
```bash
pytest --cov=ai_interlinq tests/
```

Performance benchmarks:
```bash
python examples/performance_benchmark.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the GNU General Public License v2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ›£ï¸ Roadmap

- [ ] WebSocket transport layer
- [ ] Redis pub/sub integration  
- [ ] Message persistence and replay
- [ ] Load balancing and failover
- [ ] Metrics dashboard
- [ ] CLI tools for monitoring
- [ ] Multi-language bindings

## ğŸ“ Support

- ğŸ“§ Issues: [GitHub Issues](https://github.com/mupoese/AI-Interlinq/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/mupoese/AI-Interlinq/discussions)

---

Built with â¤ï¸ for the AI community
