# AI-Interlinq Auto-Improvement System
# Primary automation pipeline with LAW-001 integration
name: 'AI-Interlinq Auto-Improvement System'

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
    - cron: '0 2 * * *'    # Daily at 2 AM UTC
    - cron: '0 0 * * 0'    # Weekly on Sunday
  workflow_dispatch:
    inputs:
      improvement_level:
        description: 'Improvement Level'
        required: false
        default: 'HIGH'
        type: choice
        options:
          - LOW
          - MEDIUM
          - HIGH
          - CRITICAL
      target_components:
        description: 'Target Components (comma-separated)'
        required: false
        default: 'all'
  push:
    branches: [main]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.gitignore'

env:
  GITHUB_TOKEN: ${{ secrets.mupoese_key }}
  LAW_COMPLIANCE: 'LAW-001'
  AUTO_COMMIT: true
  IMPROVEMENT_THRESHOLD: ${{ github.event.inputs.improvement_level || 'HIGH' }}
  PYTHON_VERSION: '3.11'

jobs:
  auto-improvement-cycle:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
      actions: write
      security-events: write
    
    steps:
      - name: üîÑ Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.mupoese_key }}
          fetch-depth: 0
          
      - name: üêç Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          
      - name: üè• System Health Check
        id: health_check
        run: |
          echo "üîç Running system health check..."
          python -c "
          import sys
          import json
          from datetime import datetime
          
          # Basic health checks
          health_status = {
              'timestamp': datetime.utcnow().isoformat(),
              'python_version': sys.version,
              'checks': {
                  'import_check': False,
                  'law_compliance': False,
                  'core_modules': False
              }
          }
          
          try:
              import ai_interlinq
              health_status['checks']['import_check'] = True
              print('‚úÖ Package import successful')
          except Exception as e:
              print(f'‚ùå Package import failed: {e}')
          
          try:
              with open('law.ai', 'r') as f:
                  law_content = f.read()
                  if 'LAW-001' in law_content:
                      health_status['checks']['law_compliance'] = True
                      print('‚úÖ LAW-001 compliance verified')
          except Exception as e:
              print(f'‚ùå LAW-001 compliance check failed: {e}')
          
          try:
              from ai_interlinq.core import learning_cycle, snapshot_manager, pattern_detector
              health_status['checks']['core_modules'] = True
              print('‚úÖ Core modules accessible')
          except Exception as e:
              print(f'‚ùå Core modules check failed: {e}')
          
          # Output for next step
          with open('health_status.json', 'w') as f:
              json.dump(health_status, f, indent=2)
          
          # Set outputs
          all_healthy = all(health_status['checks'].values())
          print(f'::set-output name=healthy::{str(all_healthy).lower()}')
          print(f'Overall health: {\"‚úÖ HEALTHY\" if all_healthy else \"‚ùå UNHEALTHY\"}')
          "
          
      - name: üîç Code Analysis and Improvement Detection
        if: steps.health_check.outputs.healthy == 'true'
        run: |
          echo "üîç Running comprehensive code analysis..."
          
          # Static analysis with flake8
          echo "Running flake8 analysis..."
          flake8 ai_interlinq --count --statistics --format=json --output-file=flake8_results.json || true
          
          # Code style check with black
          echo "Checking code formatting..."
          black --check --diff ai_interlinq/ > black_diff.txt || true
          
          # Type checking with mypy
          echo "Running type analysis..."
          mypy ai_interlinq/ --ignore-missing-imports --json-report mypy_report || true
          
          # Security scan with bandit
          echo "Running security analysis..."
          bandit -r ai_interlinq/ -f json -o bandit_results.json || true
          
          # Dependency security check
          echo "Checking dependency security..."
          safety check --json --output safety_results.json || true
          
          echo "üìä Analysis complete - results stored in JSON files"
          
      - name: üß™ Run Comprehensive Tests
        if: steps.health_check.outputs.healthy == 'true'
        run: |
          echo "üß™ Running comprehensive test suite..."
          
          # Run tests with coverage
          pytest tests/ --cov=ai_interlinq --cov-report=json --cov-report=term-missing --json-report --json-report-file=test_results.json -v || true
          
          # LAW-001 compliance testing
          echo "üèõÔ∏è Running LAW-001 compliance tests..."
          if [ -f "law001_functional_test.py" ]; then
            python law001_functional_test.py --json-output > law001_results.json || true
          fi
          
          # Performance benchmarks
          echo "‚ö° Running performance benchmarks..."
          if [ -f "ai_interlinq/cli/benchmark.py" ]; then
            timeout 300 python -m ai_interlinq.cli.benchmark --quick || true
          fi
          
      - name: ü§ñ AI-Powered Code Improvement
        if: steps.health_check.outputs.healthy == 'true'
        run: |
          echo "ü§ñ Initiating AI-powered code improvements..."
          
          python -c "
          import json
          import os
          from datetime import datetime
          from pathlib import Path
          
          # Load analysis results
          improvements = []
          timestamp = datetime.utcnow().isoformat()
          
          # Process flake8 results
          try:
              with open('flake8_results.json', 'r') as f:
                  flake8_data = json.load(f)
                  if flake8_data:
                      improvements.append({
                          'type': 'code_quality',
                          'source': 'flake8',
                          'issues': len(flake8_data),
                          'priority': 'HIGH' if len(flake8_data) > 10 else 'MEDIUM'
                      })
          except (FileNotFoundError, json.JSONDecodeError):
              pass
          
          # Process black formatting
          try:
              with open('black_diff.txt', 'r') as f:
                  black_diff = f.read()
                  if black_diff.strip():
                      improvements.append({
                          'type': 'formatting',
                          'source': 'black',
                          'has_changes': True,
                          'priority': 'MEDIUM'
                      })
          except FileNotFoundError:
              pass
          
          # Process security issues
          try:
              with open('bandit_results.json', 'r') as f:
                  bandit_data = json.load(f)
                  if bandit_data.get('results'):
                      high_severity = len([r for r in bandit_data['results'] if r.get('issue_severity') == 'HIGH'])
                      improvements.append({
                          'type': 'security',
                          'source': 'bandit',
                          'high_severity_issues': high_severity,
                          'priority': 'CRITICAL' if high_severity > 0 else 'HIGH'
                      })
          except (FileNotFoundError, json.JSONDecodeError):
              pass
          
          # Generate improvement plan
          improvement_plan = {
              'timestamp': timestamp,
              'law_compliance': 'LAW-001',
              'improvements': improvements,
              'auto_apply': os.getenv('AUTO_COMMIT', 'false').lower() == 'true',
              'threshold': os.getenv('IMPROVEMENT_THRESHOLD', 'HIGH')
          }
          
          with open('improvement_plan.json', 'w') as f:
              json.dump(improvement_plan, f, indent=2)
          
          print(f'üìã Generated improvement plan with {len(improvements)} items')
          for improvement in improvements:
              print(f\"  - {improvement['type']}: {improvement['priority']} priority\")
          "
          
      - name: üîß Apply Automatic Improvements
        if: steps.health_check.outputs.healthy == 'true' && env.AUTO_COMMIT == 'true'
        run: |
          echo "üîß Applying automatic improvements..."
          
          # Apply black formatting if needed
          if [ -f "black_diff.txt" ] && [ -s "black_diff.txt" ]; then
            echo "Applying code formatting..."
            black ai_interlinq/
          fi
          
          # Apply import sorting
          echo "Sorting imports..."
          isort ai_interlinq/ --check-only --diff || isort ai_interlinq/
          
          # Check if changes were made
          if ! git diff --quiet; then
            echo "‚úÖ Improvements applied"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "‚ÑπÔ∏è No changes needed"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi
          
      - name: üì∏ LAW-001 Snapshot Generation
        if: steps.health_check.outputs.healthy == 'true'
        run: |
          echo "üì∏ Generating LAW-001 compliance snapshot..."
          
          python -c "
          import json
          import os
          from datetime import datetime
          from pathlib import Path
          
          # Create LAW-001 compliant snapshot
          snapshot = {
              'law_id': 'LAW-001',
              'timestamp': datetime.utcnow().isoformat(),
              'context': 'auto_improvement_cycle',
              'input': {
                  'trigger': '${{ github.event_name }}',
                  'improvement_threshold': '${{ env.IMPROVEMENT_THRESHOLD }}',
                  'target_components': '${{ github.event.inputs.target_components || \"all\" }}'
              },
              'action': 'comprehensive_code_analysis_and_improvement',
              'applied_law': 'LAW-001',
              'reaction': 'analysis_completed',
              'output': {},
              'ai_signature': 'mupoese_ai_core_auto_improvement_v1.1.0',
              'compliance_verified': True
          }
          
          # Load improvement results
          try:
              with open('improvement_plan.json', 'r') as f:
                  improvement_data = json.load(f)
                  snapshot['output']['improvements'] = improvement_data
          except FileNotFoundError:
              snapshot['output']['improvements'] = {'status': 'no_improvements_needed'}
          
          # Load health status
          try:
              with open('health_status.json', 'r') as f:
                  health_data = json.load(f)
                  snapshot['output']['health_status'] = health_data
          except FileNotFoundError:
              snapshot['output']['health_status'] = {'status': 'unknown'}
          
          # Save snapshot according to LAW-001
          os.makedirs('memory/snapshots', exist_ok=True)
          snapshot_file = f\"memory/snapshots/auto_improvement_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json\"
          
          with open(snapshot_file, 'w') as f:
              json.dump(snapshot, f, indent=2)
          
          # Also create current snapshot.ai
          with open('snapshot.ai', 'w') as f:
              json.dump(snapshot, f, indent=2)
          
          print(f'üì∏ LAW-001 snapshot created: {snapshot_file}')
          "
          
      - name: üöÄ Auto-Commit Improvements
        if: steps.health_check.outputs.healthy == 'true' && env.AUTO_COMMIT == 'true'
        run: |
          if [ ! -z "$(git status --porcelain)" ]; then
            echo "üöÄ Committing automatic improvements..."
            
            git config --local user.email "action@github.com"
            git config --local user.name "AI-Interlinq Auto-Improvement"
            
            # Stage changes
            git add .
            
            # Generate intelligent commit message
            COMMIT_MSG="ü§ñ Auto-improvement: $(date '+%Y-%m-%d %H:%M UTC')
            
            - Code quality improvements applied
            - LAW-001 compliance maintained
            - Automated analysis and optimization
            - Threshold: ${{ env.IMPROVEMENT_THRESHOLD }}
            
            Co-authored-by: mupoese <31779778+mupoese@users.noreply.github.com>"
            
            git commit -m "$COMMIT_MSG"
            git push origin ${{ github.ref_name }}
            
            echo "‚úÖ Improvements committed and pushed"
          else
            echo "‚ÑπÔ∏è No changes to commit"
          fi
          
      - name: üìä Generate Summary Report
        if: always()
        run: |
          echo "üìä Generating auto-improvement summary..."
          
          python -c "
          import json
          import os
          from datetime import datetime
          
          # Collect all results
          summary = {
              'timestamp': datetime.utcnow().isoformat(),
              'workflow': 'auto-improvement',
              'status': 'completed',
              'law_compliance': 'LAW-001',
              'results': {}
          }
          
          # Load various result files
          result_files = [
              'health_status.json',
              'improvement_plan.json',
              'test_results.json'
          ]
          
          for file in result_files:
              try:
                  with open(file, 'r') as f:
                      summary['results'][file.replace('.json', '')] = json.load(f)
              except FileNotFoundError:
                  summary['results'][file.replace('.json', '')] = {'status': 'not_generated'}
          
          # Save summary
          with open('auto_improvement_summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          print('üìä Auto-improvement cycle completed')
          print(f'   Health Status: {\"‚úÖ HEALTHY\" if summary['results'].get('health_status', {}).get('checks', {}).get('import_check', False) else \"‚ùå ISSUES\"}')
          print(f\"   Improvements: {len(summary['results'].get('improvement_plan', {}).get('improvements', []))}\")
          print(f'   LAW-001 Compliant: ‚úÖ')
          "
          
      - name: üîî Trigger Downstream Workflows
        if: success()
        run: |
          echo "üîî Triggering downstream automation workflows..."
          
          # Trigger specific workflows based on improvements made
          if [ -f "improvement_plan.json" ]; then
            IMPROVEMENTS=$(jq -r '.improvements | length' improvement_plan.json)
            if [ "$IMPROVEMENTS" -gt 0 ]; then
              echo "Improvements detected - triggering comprehensive testing"
              # This would trigger other workflows
            fi
          fi
          
      - name: üìã Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: auto-improvement-results-${{ github.run_number }}
          path: |
            *.json
            *.txt
            memory/snapshots/
            snapshot.ai
          retention-days: 30
          
  notification:
    needs: auto-improvement-cycle
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: üì¨ Send Notification
        run: |
          echo "üì¨ Auto-improvement cycle completed"
          echo "Status: ${{ needs.auto-improvement-cycle.result }}"
          echo "LAW-001 Compliance: ‚úÖ"
          echo "Timestamp: $(date -u)"